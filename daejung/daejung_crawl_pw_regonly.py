# -*- coding: utf-8 -*-
"""
ëŒ€ì • ê²€ìƒ‰ ìµœì†ŒíŒ (HTTP-only, q= ê³ ì •)
- ê²€ìƒ‰: GET /02_product/search/?q=í‚¤ì›Œë“œ
- ì²« í–‰ì—ì„œ code/price/stock/idx ì¶”ì¶œ
- íŒì—…: GET /02_product/search/popup/?idx=XXXX ë¡œ labels ì¶”ì¶œ
- ì¶œë ¥: brand, code, price, discount_price(10%â†“, 100ì› ë°˜ì˜¬ë¦¼), stock_label, labels
"""

import urllib.request, urllib.parse, urllib.error
import re, json, html as htmllib
from decimal import Decimal, ROUND_HALF_UP

BASE = "https://www.daejungchem.co.kr"
SEARCH_URL = f"{BASE}/02_product/search/"
POPUP_PREFIX = f"{BASE}/02_product/search/popup/?idx="  # ì˜ˆ: ...?idx=6963

HDRS = {
    "User-Agent": ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                   "AppleWebKit/537.36 (KHTML, like Gecko) "
                   "Chrome/123.0.0.0 Safari/537.36"),
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
    "Connection": "close",
    "Referer": SEARCH_URL,
}

# tbody ë‚´ ì²« tr ê¸°ì¤€ìœ¼ë¡œ íŒŒì‹± (0-based ì¸ë±ìŠ¤)
TD_IDX = {"cas":1, "code":2, "name":3, "pack":5, "price":7, "stock":8}
RX_INT  = re.compile(r"(\d[\d,]*)")
RX_IDX  = re.compile(r"/popup/\?idx=([0-9]{4})")
KEEP_KEYS = (
    "ê¸°ì¡´ë¬¼ì§ˆ","ìœ í•´","ìœ í•´í™”í•™ë¬¼ì§ˆ","ì‹ ê·œí™”í•™ë¬¼ì§ˆ",
    "ìœ„í—˜","ê·œì œ","ê´€ê³„ë²•ë ¹","ì‚°ì—…ì•ˆì „ë³´ê±´ë²•","í™”í•™ë¬¼ì§ˆ","Remark"
)

def http_get(url: str, timeout=12) -> bytes | None:
    try:
        req = urllib.request.Request(url, headers=HDRS)
        with urllib.request.urlopen(req, timeout=timeout) as r:
            return r.read()
    except Exception:
        return None

def decode_html(raw: bytes | None) -> str:
    if not raw:
        return ""
    try:
        return raw.decode("utf-8")
    except Exception:
        pass
    try:
        return raw.decode("cp949")
    except Exception:
        return raw.decode("utf-8", "replace")

def strip_tags(s: str) -> str:
    s = re.sub(r"<[^>]+>", "", s)
    s = s.replace("&nbsp;", " ").replace("\xa0", " ")
    return htmllib.unescape(s).strip()

def parse_int(s: str) -> int | None:
    m = RX_INT.search(s or "")
    return int(m.group(1).replace(",", "")) if m else None

def discount_round(price: int | None, rate=0.10, unit=100) -> int | None:
    if price is None:
        return None
    val = Decimal(price) * Decimal(1 - rate)
    return int((val / unit).quantize(Decimal("1"), rounding=ROUND_HALF_UP) * unit)

def submit_search(q: str) -> str:
    url = SEARCH_URL + "?" + urllib.parse.urlencode({"q": q})
    return decode_html(http_get(url))

def parse_first_row(html: str) -> dict | None:
    # ì²« tbody > tr í•˜ë‚˜ë§Œ ì¶”ì¶œ
    m = re.search(r"<tbody[^>]*>(.*?)</tbody>", html, flags=re.S|re.I)
    if not m:
        return None
    tbody = m.group(1)
    m2 = re.search(r"<tr[^>]*>(.*?)</tr>", tbody, flags=re.S|re.I)
    if not m2:
        return None
    row_html = m2.group(1)

    # ëª¨ë“  td íŒŒì‹±
    tds = re.findall(r"<td[^>]*>(.*?)</td>", row_html, flags=re.S|re.I)
    if len(tds) <= TD_IDX["stock"]:
        return None

    code = strip_tags(tds[TD_IDX["code"]]) or None
    price = parse_int(strip_tags(tds[TD_IDX["price"]]))
    stock_label = strip_tags(tds[TD_IDX["stock"]])

    # idx (íŒì—… ë§í¬ì—ì„œ ì¶”ì¶œ)
    m_idx = RX_IDX.search(row_html)
    idx = m_idx.group(1) if m_idx else None

    return {
        "brand": "ëŒ€ì •í™”ê¸ˆ",
        "code": code,
        "price": price,
        "discount_price": discount_round(price, unit=100),
        "stock_label": stock_label,
        "idx": idx,
    }

def fetch_labels(idx: str) -> list[str]:
    html = decode_html(http_get(POPUP_PREFIX + idx))
    if not html:
        return []
    # íƒœê·¸ ì œê±° â†’ ë¼ì¸ ë¶„í•´
    text = strip_tags(html)
    lines = [ln.strip() for ln in re.split(r"[\r\n]+", text) if ln.strip()]
    kept = [ln for ln in lines if any(k in ln for k in KEEP_KEYS)]
    # ì¤‘ë³µ ì œê±°
    seen, out = set(), []
    for ln in kept:
        n = re.sub(r"\s+", " ", ln)
        if n not in seen:
            out.append(n); seen.add(n)
    return out

def search_minimal(q: str, first_only=True, include_labels=True):
    html = submit_search(q)
    row = parse_first_row(html)
    if not row:
        return []
    labels = []
    if include_labels and row.get("idx"):
        labels = fetch_labels(row["idx"])
    return [{
        "brand": row["brand"],
        "code": row["code"],
        "price": row["price"],
        "discount_price": row["discount_price"],
        "stock_label": row["stock_label"],
        "labels": labels,
    }]

if __name__ == "__main__":
    try:
        kw = input("ğŸ” ëŒ€ì • ì œí’ˆì½”ë“œ/í‚¤ì›Œë“œ: ").strip()
    except EOFError:
        kw = ""
    data = search_minimal(kw or "ì—íƒ„ì˜¬", first_only=True, include_labels=True)
    print(json.dumps(data, ensure_ascii=False, indent=2) if data else "âŒ ê²°ê³¼ ì—†ìŒ")
